# üöÄ TRACKING V2 - ROADMAP ELITE

**Data:** 2025-10-21  
**Vers√£o Atual:** V1 (IP/UA/Session b√°sico)  
**Pr√≥xima Vers√£o:** V2 (Intelligence Layer)  
**Target:** TOP 0.1% - Enterprise Grade

---

## **üéØ VIS√ÉO GERAL:**

Tracking V2 transforma dados brutos (IP, User-Agent) em **intelig√™ncia acion√°vel**:
- Segmenta√ß√£o por localiza√ß√£o geogr√°fica
- Perfis anal√≠ticos de usu√°rio
- Detec√ß√£o automatizada de bots/scrapers
- Compliance LGPD/GDPR by design
- Fallback resiliente para Redis failures

---

## **üìã FEATURES PLANEJADAS:**

### **1. HASH SEGURO DE IP (LGPD Compliance)**

#### **Problema:**
- Armazenar IP completo = dado pessoal sens√≠vel
- LGPD exige minimiza√ß√£o de dados
- Precisamos balance entre tracking e privacidade

#### **Solu√ß√£o:**
```python
import hashlib
import os

def hash_ip_securely(ip_address, salt=None):
    """
    Hash IP com salt secreto para compliance LGPD
    
    Benef√≠cios:
    - IP n√£o √© revers√≠vel
    - Ainda podemos detectar m√∫ltiplos acessos do mesmo IP
    - Compliance total com LGPD Art. 6¬∫ (minimiza√ß√£o)
    """
    if not salt:
        salt = os.environ.get('IP_HASH_SALT', 'default_salt_change_me')
    
    ip_with_salt = f"{ip_address}{salt}"
    hashed = hashlib.sha256(ip_with_salt.encode()).hexdigest()
    
    # Retornar apenas primeiros 16 caracteres (suficiente para identifica√ß√£o)
    return hashed[:16]

# Uso:
bot_user.ip_hash = hash_ip_securely(user_ip)
bot_user.ip_address = None  # N√£o salvar IP em texto claro
```

#### **Implementa√ß√£o:**
- Adicionar campo `ip_hash` ao BotUser
- Manter `ip_address` apenas para debug (deletar ap√≥s 7 dias)
- Usar `ip_hash` para analytics e detec√ß√£o de fraudes

#### **Benef√≠cios:**
- ‚úÖ LGPD compliant
- ‚úÖ Ainda detecta m√∫ltiplos acessos
- ‚úÖ Imposs√≠vel reverter para IP original
- ‚úÖ Pode ser usado em relat√≥rios p√∫blicos

---

### **2. GEO IP MAPPING (Localiza√ß√£o Geogr√°fica)**

#### **Problema:**
- IP sozinho n√£o diz nada sobre onde usu√°rio est√°
- Precisamos saber cidade/estado para:
  - Segmenta√ß√£o de remarketing por regi√£o
  - Detectar fraudes (IP de pa√≠s diferente do esperado)
  - Analytics de performance por regi√£o

#### **Solu√ß√£o:**
```python
import geoip2.database
import geoip2.errors

def get_geo_from_ip(ip_address):
    """
    Resolve IP para cidade/estado/pa√≠s usando MaxMind GeoLite2
    
    Retorna:
        {
            'city': 'S√£o Paulo',
            'state': 'SP',
            'country': 'BR',
            'latitude': -23.5505,
            'longitude': -46.6333
        }
    """
    try:
        reader = geoip2.database.Reader('/path/to/GeoLite2-City.mmdb')
        response = reader.city(ip_address)
        
        return {
            'city': response.city.name or 'Unknown',
            'state': response.subdivisions.most_specific.iso_code if response.subdivisions else None,
            'country': response.country.iso_code,
            'latitude': response.location.latitude,
            'longitude': response.location.longitude
        }
    except geoip2.errors.AddressNotFoundError:
        return {'city': 'Unknown', 'state': None, 'country': 'XX'}

# Uso no redirect:
geo_data = get_geo_from_ip(user_ip)
# Salvar no Redis junto com tracking_data
tracking_data['geo'] = geo_data
```

#### **Implementa√ß√£o:**
- Instalar MaxMind GeoLite2 (gr√°tis, precisa cadastro)
- Adicionar campos `geo_city`, `geo_state`, `geo_country` ao BotUser
- Capturar no redirect e salvar no Redis
- Associar ao BotUser quando /start

#### **Benef√≠cios:**
- ‚úÖ Remarketing segmentado por regi√£o
- ‚úÖ Detectar fraudes (ex: an√∫ncio para SP, lead do Marrocos)
- ‚úÖ Analytics por cidade/estado
- ‚úÖ Otimizar gastos de an√∫ncios por regi√£o

#### **Casos de Uso:**
```python
# Remarketing apenas para SP
leads_sp = BotUser.query.filter_by(geo_state='SP', purchased=False)

# Detectar anomalias
suspicious = BotUser.query.filter(BotUser.geo_country != 'BR')

# Comparar performance por regi√£o
conversion_by_state = db.session.query(
    BotUser.geo_state,
    func.count(Payment.id).label('sales')
).join(Payment).group_by(BotUser.geo_state)
```

---

### **3. USER-AGENT PARSING (Dispositivo/Browser/OS)**

#### **Problema:**
- User-Agent √© string crua: `Mozilla/5.0 (iPhone; CPU iPhone OS 14_7_1...)`
- Precisamos extrair: dispositivo, navegador, OS, vers√£o

#### **Solu√ß√£o:**
```python
from user_agents import parse

def parse_user_agent(ua_string):
    """
    Parse User-Agent para extrair informa√ß√µes estruturadas
    
    Retorna:
        {
            'device': 'iPhone',
            'browser': 'Safari',
            'browser_version': '14.1',
            'os': 'iOS',
            'os_version': '14.7.1',
            'is_mobile': True,
            'is_tablet': False,
            'is_pc': False,
            'is_bot': False
        }
    """
    ua = parse(ua_string)
    
    return {
        'device': ua.device.family,
        'browser': ua.browser.family,
        'browser_version': ua.browser.version_string,
        'os': ua.os.family,
        'os_version': ua.os.version_string,
        'is_mobile': ua.is_mobile,
        'is_tablet': ua.is_tablet,
        'is_pc': ua.is_pc,
        'is_bot': ua.is_bot
    }

# Uso:
ua_data = parse_user_agent(user_agent)
bot_user.device_type = ua_data['device']
bot_user.browser_name = ua_data['browser']
bot_user.os_name = ua_data['os']
bot_user.is_mobile = ua_data['is_mobile']
bot_user.is_bot_detected = ua_data['is_bot']
```

#### **Implementa√ß√£o:**
- Instalar `user-agents` library: `pip install pyyaml ua-parser user-agents`
- Adicionar campos ao BotUser:
  - `device_type` (iPhone, Samsung, etc)
  - `browser_name` (Chrome, Safari, etc)
  - `os_name` (iOS, Android, Windows)
  - `is_mobile` (boolean)
  - `is_bot_detected` (boolean)
- Parse no redirect e salvar no Redis
- Associar ao BotUser quando /start

#### **Benef√≠cios:**
- ‚úÖ Segmentar remarketing por dispositivo
- ‚úÖ Detectar bots automaticamente
- ‚úÖ Otimizar landing pages por plataforma
- ‚úÖ Analytics de convers√£o por dispositivo

#### **Casos de Uso:**
```python
# Remarketing apenas para mobile
mobile_users = BotUser.query.filter_by(is_mobile=True, purchased=False)

# Detectar bots
bots = BotUser.query.filter_by(is_bot_detected=True)

# Comparar convers√£o iOS vs Android
ios_conversion = Payment.query.join(BotUser).filter(BotUser.os_name == 'iOS').count()
android_conversion = Payment.query.join(BotUser).filter(BotUser.os_name == 'Android').count()
```

---

### **4. PERFIL ANAL√çTICO DO USU√ÅRIO**

#### **Problema:**
- Dados isolados (IP, UA, geo) n√£o contam hist√≥ria completa
- Precisamos perfil √∫nico agregando tudo

#### **Solu√ß√£o:**
```python
class UserAnalyticalProfile:
    """
    Perfil anal√≠tico completo do usu√°rio
    
    Agrega:
    - Dados demogr√°ficos (geo)
    - Dados t√©cnicos (dispositivo, browser)
    - Dados comportamentais (tempo click ‚Üí start, hor√°rio de acesso)
    - Scores de qualidade (bot score, fraud score)
    """
    
    @staticmethod
    def generate(bot_user):
        profile = {
            # Demogr√°fico
            'location': {
                'city': bot_user.geo_city,
                'state': bot_user.geo_state,
                'country': bot_user.geo_country
            },
            
            # T√©cnico
            'device': {
                'type': bot_user.device_type,
                'os': bot_user.os_name,
                'browser': bot_user.browser_name,
                'is_mobile': bot_user.is_mobile
            },
            
            # Comportamental
            'behavior': {
                'click_to_start_seconds': (bot_user.first_interaction - bot_user.click_timestamp).total_seconds() if bot_user.click_timestamp else None,
                'access_hour': bot_user.first_interaction.hour,
                'access_day_of_week': bot_user.first_interaction.weekday()
            },
            
            # Scores
            'quality': {
                'bot_score': UserAnalyticalProfile._calculate_bot_score(bot_user),
                'fraud_score': UserAnalyticalProfile._calculate_fraud_score(bot_user)
            }
        }
        
        return profile
    
    @staticmethod
    def _calculate_bot_score(bot_user):
        """Retorna 0-100, onde 100 = certeza de bot"""
        score = 0
        
        # User-Agent indica bot
        if bot_user.is_bot_detected:
            score += 50
        
        # M√∫ltiplos acessos do mesmo IP em < 1 min
        similar_users = BotUser.query.filter_by(ip_hash=bot_user.ip_hash).filter(
            BotUser.first_interaction >= bot_user.first_interaction - timedelta(minutes=1)
        ).count()
        if similar_users > 5:
            score += 30
        
        # Click ‚Üí Start muito r√°pido (< 2s)
        if bot_user.click_timestamp:
            diff = (bot_user.first_interaction - bot_user.click_timestamp).total_seconds()
            if diff < 2:
                score += 20
        
        return min(score, 100)
    
    @staticmethod
    def _calculate_fraud_score(bot_user):
        """Retorna 0-100, onde 100 = certeza de fraude"""
        score = 0
        
        # Pa√≠s diferente do esperado
        if bot_user.geo_country != 'BR':
            score += 40
        
        # Sem fbclid (n√£o veio de an√∫ncio leg√≠timo)
        if not bot_user.fbclid:
            score += 30
        
        # Acesso fora de hor√°rio comercial (3am-6am)
        if 3 <= bot_user.first_interaction.hour <= 6:
            score += 20
        
        # Bot detectado
        if bot_user.is_bot_detected:
            score += 10
        
        return min(score, 100)
```

#### **Implementa√ß√£o:**
- Criar tabela `UserProfile` com JSON field para armazenar perfil
- Gerar perfil ass√≠ncrono (Celery task) ap√≥s /start
- Exibir perfil no admin panel
- Usar scores para filtrar leads suspeitos

#### **Benef√≠cios:**
- ‚úÖ Vis√£o 360¬∞ do usu√°rio
- ‚úÖ Detectar fraudes automaticamente
- ‚úÖ Segmenta√ß√£o avan√ßada
- ‚úÖ Insights acion√°veis

---

### **5. FALLBACK RESILIENTE (Redis Failures)**

#### **Problema:**
- Se Redis cair, tracking para de funcionar
- Perdemos dados cr√≠ticos de IP/UA

#### **Solu√ß√£o:**
```python
class TrackingStorageFallback:
    """
    Sistema de fallback com m√∫ltiplos backends:
    1. Redis (prim√°rio, r√°pido)
    2. Memcached (fallback 1, se Redis falhar)
    3. PostgreSQL temp table (fallback 2, se ambos falharem)
    4. Log file (fallback 3, √∫ltimo recurso)
    """
    
    @staticmethod
    def save(fbclid, tracking_data):
        # Tentar Redis
        try:
            import redis
            r = redis.Redis(host='localhost', port=6379, decode_responses=True)
            r.setex(f'tracking:{fbclid}', 180, json.dumps(tracking_data))
            logger.info(f"‚úÖ Tracking salvo no Redis")
            return True
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Redis falhou: {e}, tentando fallback...")
        
        # Tentar Memcached
        try:
            import memcache
            mc = memcache.Client(['127.0.0.1:11211'])
            mc.set(f'tracking:{fbclid}', json.dumps(tracking_data), time=180)
            logger.info(f"‚úÖ Tracking salvo no Memcached (fallback 1)")
            return True
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Memcached falhou: {e}, tentando DB...")
        
        # Tentar DB temp
        try:
            from models import TrackingTemp
            temp = TrackingTemp(
                fbclid=fbclid,
                data=json.dumps(tracking_data),
                expires_at=datetime.now() + timedelta(seconds=180)
            )
            db.session.add(temp)
            db.session.commit()
            logger.info(f"‚úÖ Tracking salvo no DB temp (fallback 2)")
            return True
        except Exception as e:
            logger.error(f"‚ùå DB temp falhou: {e}, salvando em log...")
        
        # √öltimo recurso: log file
        try:
            with open('logs/tracking_fallback.jsonl', 'a') as f:
                f.write(json.dumps({
                    'fbclid': fbclid,
                    'data': tracking_data,
                    'timestamp': datetime.now().isoformat()
                }) + '\n')
            logger.warning(f"‚ö†Ô∏è Tracking salvo em log file (fallback 3)")
            return True
        except Exception as e:
            logger.critical(f"üö® TODOS OS FALLBACKS FALHARAM: {e}")
            return False
    
    @staticmethod
    def load(fbclid):
        # Tentar Redis
        try:
            import redis
            r = redis.Redis(host='localhost', port=6379, decode_responses=True)
            data = r.get(f'tracking:{fbclid}')
            if data:
                return json.loads(data)
        except:
            pass
        
        # Tentar Memcached
        try:
            import memcache
            mc = memcache.Client(['127.0.0.1:11211'])
            data = mc.get(f'tracking:{fbclid}')
            if data:
                return json.loads(data)
        except:
            pass
        
        # Tentar DB temp
        try:
            from models import TrackingTemp
            temp = TrackingTemp.query.filter_by(fbclid=fbclid).first()
            if temp and temp.expires_at > datetime.now():
                return json.loads(temp.data)
        except:
            pass
        
        return None
```

#### **Implementa√ß√£o:**
- Criar tabela `TrackingTemp` para fallback DB
- Implementar classe `TrackingStorageFallback`
- Substituir chamadas diretas ao Redis por fallback
- Adicionar cronjob para limpar `TrackingTemp` expirados

#### **Benef√≠cios:**
- ‚úÖ 99.99% uptime do tracking
- ‚úÖ Zero perda de dados cr√≠ticos
- ‚úÖ Degrada√ß√£o graciosa
- ‚úÖ Recupera√ß√£o autom√°tica

---

## **üìä ROADMAP DE IMPLEMENTA√á√ÉO:**

### **Sprint 1 (Semana 1):**
- [ ] Hash seguro de IP (LGPD)
- [ ] Geo IP mapping (MaxMind)
- [ ] User-Agent parsing
- [ ] Migration para novos campos

### **Sprint 2 (Semana 2):**
- [ ] Perfil anal√≠tico
- [ ] Bot score calculator
- [ ] Fraud score calculator
- [ ] Admin panel para visualizar perfis

### **Sprint 3 (Semana 3):**
- [ ] Fallback resiliente
- [ ] TrackingTemp model
- [ ] Cronjob de limpeza
- [ ] Testes de chaos engineering

### **Sprint 4 (Semana 4):**
- [ ] Dashboard de analytics
- [ ] Segmenta√ß√£o avan√ßada
- [ ] Relat√≥rios automatizados
- [ ] Documenta√ß√£o completa

---

## **üéØ M√âTRICAS DE SUCESSO:**

- **Taxa de captura:** > 95%
- **Taxa de match:** > 90%
- **Uptime tracking:** > 99.9%
- **Lat√™ncia adicional:** < 5ms
- **Taxa de bot detection:** > 80% precision
- **Taxa de fraud detection:** > 70% precision

---

## **üí∞ CUSTO ESTIMADO:**

- MaxMind GeoLite2: **Gr√°tis** (at√© 1000 req/dia)
- Redis: **$0** (j√° instalado)
- Memcached: **$0** (fallback opcional)
- Storage adicional: **~500MB/m√™s** (neglig√≠vel)
- Processamento: **+2% CPU** (parsing UA/Geo)

**ROI:** Aumento de 15-30% na qualidade dos leads = vale cada centavo

---

**ISSO √â TRACKING V2. ISSO √â INTELIG√äNCIA ACION√ÅVEL.** üöÄ

